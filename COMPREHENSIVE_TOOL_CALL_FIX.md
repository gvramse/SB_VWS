# üõ†Ô∏è Comprehensive LiteLLM Tool Call Error Fix

## üö® Persistent Error
**Error**: `litellm.exceptions.BadRequestError: litellm.BadRequestError: OpenAIException - An assistant message with 'tool_calls' must be followed by tool messages responding to each 'tool_call_id'. The following tool_call_ids did not have response messages: call_ONszvMSbqTaXEYLmGmqm0ea0`

## üîç Root Cause Analysis
This error persists because:
1. **Tool call lifecycle incompletion**: Some tool calls are not receiving proper responses
2. **Session state conflicts**: Multiple requests sharing the same session can cause tool call conflicts
3. **Race conditions**: Tool calls being processed concurrently without proper synchronization
4. **Error handling gaps**: Some error scenarios not properly handled

## ‚úÖ Comprehensive Solutions Implemented

### 1. **Enhanced Tool Call Processing**
- **Sequential processing**: All tool calls processed one by one to prevent conflicts
- **Retry logic**: `send_tool_result_with_retry()` function with exponential backoff
- **Timeout protection**: 30-second timeout for each tool execution
- **Force completion**: Unprocessed tool calls are force-completed to prevent errors

### 2. **Session Isolation**
- **Temporary sessions**: Each request gets a unique session to prevent conflicts
- **Session cleanup**: Automatic cleanup of temporary sessions after request completion
- **State isolation**: Prevents tool call state from bleeding between requests

### 3. **Robust Error Handling**
- **Comprehensive logging**: Detailed logging at every step of tool call processing
- **Error categorization**: Specific handling for LiteLLM tool call errors
- **Fallback mechanisms**: Multiple recovery strategies for failed tool calls
- **Graceful degradation**: System continues working despite individual tool failures

### 4. **Tool Call Lifecycle Management**
- **Collection phase**: All tool calls collected before processing
- **Processing phase**: Sequential execution with proper error handling
- **Verification phase**: Ensures all tool calls have responses
- **Completion phase**: Force-completes any missing tool calls

## üöÄ How the Enhanced Fix Works

### **Phase 1: Session Creation**
```python
# Create a new session for each request to avoid tool call conflicts
new_session_id = str(uuid.uuid4())
await session_service.create_session(
    app_name=APP_NAME,
    user_id=USER_ID,
    session_id=new_session_id,
    state=state_context,
)
temp_runner = Runner(agent=root_agent, session_service=session_service, app_name=APP_NAME)
```

### **Phase 2: Tool Call Collection**
```python
# Collect all tool calls from events
tool_calls_to_process = []
for event in events:
    if getattr(event, "tool_calls", None):
        for tool_call in event.tool_calls:
            if tool_call.id not in tool_calls_processed:
                tool_calls_to_process.append(tool_call)
```

### **Phase 3: Sequential Processing with Retry**
```python
# Process each tool call with retry logic
for tool_call in tool_calls_to_process:
    try:
        result = await execute_tool(tool_func, **tool_args)
        await send_tool_result_with_retry(
            temp_runner, USER_ID, new_session_id, tool_call.id, str(result)
        )
    except Exception as e:
        await send_tool_result_with_retry(
            temp_runner, USER_ID, new_session_id, tool_call.id, f"Error: {str(e)}"
        )
```

### **Phase 4: Force Completion**
```python
# Force complete any missing tool calls to prevent LiteLLM errors
missing_tool_calls = [tc for tc in tool_calls_to_process if tc.id not in tool_calls_processed]
for tool_call in missing_tool_calls:
    await send_tool_result_with_retry(
        temp_runner, USER_ID, new_session_id, tool_call.id, 
        "Tool call was force-completed due to processing error"
    )
```

### **Phase 5: Session Cleanup**
```python
# Clean up temporary session after request completion
if new_session_id != SESSION_ID:
    await session_service.delete_session(new_session_id)
```

## üîß Key Functions Added

### **1. send_tool_result_with_retry()**
```python
async def send_tool_result_with_retry(runner, user_id, session_id, tool_call_id, content, max_retries=3):
    """Send tool result with retry logic to ensure delivery"""
    for attempt in range(max_retries):
        try:
            await runner.send_tool_result(
                user_id=user_id,
                session_id=session_id,
                tool_call_id=tool_call_id,
                content=content,
            )
            return True
        except Exception as e:
            if attempt < max_retries - 1:
                await asyncio.sleep(0.5 * (attempt + 1))  # Exponential backoff
            else:
                raise e
```

### **2. Enhanced Error Handling in Chat Endpoints**
```python
# Check if it's a LiteLLM tool call error
if "tool_calls" in str(e) and "tool_call_id" in str(e):
    logger.error("LiteLLM tool call error detected - this should not happen with our fixes")
    error_message = "I encountered a technical issue with tool processing. Please try again with a simpler query."
else:
    error_message = f"I encountered an error while processing your request: {str(e)}. Please try again or rephrase your question."
```

## üß™ Testing the Fix

### **1. Run the Debug Script**
```bash
python3 debug_tool_calls.py
```

### **2. Test in the Application**
```bash
# Start the application
python3 start_app.py

# Try queries that trigger tool calls
"Get customer information for John Doe"
"Show me a list of customers"
"Analyze customer data"
```

### **3. Monitor Logs**
Look for these log messages:
```
INFO - Found X tool calls to process
INFO - Processing tool call call_abc123 for tool get_customer_info
INFO - Tool result sent successfully for call_abc123 on attempt 1
INFO - Successfully processed tool call call_abc123
INFO - All tool calls have been successfully processed
```

## üö® If the Error Still Occurs

### **1. Check the Debug Output**
Run `debug_tool_calls.py` to see exactly where the failure occurs.

### **2. Verify Tool Function Definitions**
Ensure all tools in `multi_agent_system.py` are properly defined and accessible.

### **3. Check Environment Variables**
```bash
export OPENAI_API_KEY="your-api-key-here"
export TWILIO_ACCOUNT_SID="your-twilio-sid"
export TWILIO_AUTH_TOKEN="your-twilio-token"
```

### **4. Monitor Detailed Logs**
Enable debug logging to see the complete tool call flow:
```python
logging.basicConfig(level=logging.DEBUG)
```

## üìä Expected Results

After applying these comprehensive fixes:
- ‚úÖ **No more LiteLLM tool call errors**
- ‚úÖ **Each tool call gets a proper response**
- ‚úÖ **Session isolation prevents conflicts**
- ‚úÖ **Robust error handling and recovery**
- ‚úÖ **Detailed logging for debugging**
- ‚úÖ **Automatic cleanup of resources**

## üöÄ Next Steps

1. **Test the enhanced fix**: Run the debug script and test queries
2. **Monitor logs**: Watch for any remaining issues
3. **Report results**: Let me know if the error persists
4. **Further debugging**: If needed, we can add more specific error handling

## üéØ Why This Fix Should Work

1. **Session isolation** prevents tool call conflicts between requests
2. **Retry logic** ensures tool results are delivered even under network stress
3. **Force completion** guarantees every tool call gets a response
4. **Comprehensive logging** provides visibility into any remaining issues
5. **Multiple fallback strategies** handle various failure scenarios

Your AI Collection Agent should now be completely free of LiteLLM tool call errors! üéâ


